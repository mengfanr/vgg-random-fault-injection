{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "from keras.models import load_model\n",
    "\n",
    "vgg_path_str_old = 'vgg_19_0519'\n",
    "vgg_path_str_new = 'vgg_19_10'\n",
    "# model_vgg19 = VGG19(weights='imagenet')\n",
    "# model_vgg19.summary()\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'vgg19_saved_models')\n",
    "model_path = os.path.join(save_dir, vgg_path_str_old+'.h5')\n",
    "model_vgg19 = load_model(model_path)\n",
    "total_layer = model_vgg19.layers\n",
    "layer_index_size = 19\n",
    "original_size = 143667240\n",
    "\n",
    "N_bit = 16\n",
    "fault_ratio = 0.005\n",
    "random_bit_flip_position = [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768]\n",
    "global_gap = (2**N_bit)-1\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "for iteration in range(20):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    weights_store = []\n",
    "    weights_store_float_to_int = np.zeros(original_size,dtype = int)\n",
    "    weights_store_int_to_float = []\n",
    "    layer_weight_size = np.zeros(layer_index_size*2,dtype = int)\n",
    "    for layer_index in range(np.size(total_layer)):\n",
    "        layer_weight_load = model_vgg19.layers[layer_index].get_weights() \n",
    "        if(len(layer_weight_load) > 0):\n",
    "#             print('aaaaaaaaaaaaaaaaaaa')\n",
    "            model_original_weights = layer_weight_load[0]\n",
    "            model_original_bias = layer_weight_load[1]\n",
    "            size_model_weights = np.size(model_original_weights)\n",
    "            size_model_bias = np.size(model_original_bias)\n",
    "            layer_weight_size[i] = size_model_weights\n",
    "            i = i+1\n",
    "            layer_weight_size[i] = size_model_bias\n",
    "            i = i+1\n",
    "            shape_model_weights = np.shape(model_original_weights)\n",
    "            resized_model_weights = np.reshape(model_original_weights,(size_model_weights))\n",
    "            weights_store_temp = np.append(resized_model_weights,model_original_bias)\n",
    "            weights_store = np.append(weights_store,weights_store_temp)\n",
    "    # print(layer_weight_size)\n",
    "    # print(np.shape(weights_store))\n",
    "    #####################################arrray reshape complete ######################################\n",
    "    #####################################float convert to int and convert back start#####################################\n",
    "    max_in_weights = np.max(weights_store)\n",
    "    min_in_weights = np.min(weights_store)\n",
    "    weights_store_float_to_int = np.around((weights_store-min_in_weights)/(max_in_weights-min_in_weights)*global_gap)\n",
    "    weights_store_float_to_int = weights_store_float_to_int.astype(np.int)\n",
    "    weights_store_int_max = np.max(weights_store_float_to_int)\n",
    "    weights_store_int_min = np.min(weights_store_float_to_int)\n",
    "    weights_store_int_to_float = weights_store_float_to_int/global_gap*(max_in_weights-min_in_weights)+min_in_weights\n",
    "    weights_store_int_to_float = weights_store_int_to_float.astype(np.float32)\n",
    "    difference_check = weights_store-weights_store_int_to_float\n",
    "    difference_location = np.where(difference_check>(abs(max_in_weights-min_in_weights)/64))\n",
    "    if np.size(difference_location)>0:\n",
    "        print('conversion has error, certain value is out of threshold:',np.size(difference_location))\n",
    "    ############################### random fault injection start ###################################\n",
    "    fault_position_record = {}\n",
    "    inject_index = [random.randint(0, np.size(weights_store_int_to_float)-1) for __ in range(math.ceil(np.size(weights_store_int_to_float)*fault_ratio))]\n",
    "    for fault_index in inject_index:\n",
    "        temp_weight_int_before_inject = np.around((weights_store_int_to_float[fault_index]-min_in_weights)/(max_in_weights-min_in_weights)*global_gap)\n",
    "        temp_weight_int_before_inject = temp_weight_int_before_inject.astype(np.int)\n",
    "    ############################## start inject ###############################################\n",
    "        random_change_position = random.choice(random_bit_flip_position) #randomly choose one bit\n",
    "\n",
    "    ############################ store index ###############################################\n",
    "        inject_key = fault_index\n",
    "        inject_value = [random_change_position]\n",
    "        if not(inject_key in fault_position_record): # if no key add one\n",
    "            fault_position_record[inject_key] = inject_value\n",
    "            temp_weight_int_before_inject = temp_weight_int_before_inject ^ random_change_position\n",
    "        else: #if has a key check the position\n",
    "            while(random_change_position in fault_position_record[inject_key]):\n",
    "                random_change_position = random.choice(random_bit_flip_position)\n",
    "            fault_position_record[inject_key].append(random_change_position)\n",
    "            temp_weight_int_before_inject = temp_weight_int_before_inject ^ random_change_position\n",
    "    ############################## end inject #################################################\n",
    "        temp_weight_int_after_inject = temp_weight_int_before_inject/global_gap*(max_in_weights-min_in_weights)+min_in_weights\n",
    "        temp_weight_int_after_inject = temp_weight_int_after_inject.astype(np.float32)\n",
    "    ###################################### fault injection end ###################################\n",
    "        weights_store_int_to_float[fault_index] = temp_weight_int_after_inject\n",
    "#     print('size of the fault position record:',len(fault_position_record))\n",
    "    if sum([len(l) for l in fault_position_record.values()])- original_size*fault_ratio>1:\n",
    "        print('compare:\\n',sum([len(l) for l in fault_position_record.values()]),'and', original_size*fault_ratio)\n",
    "    ############################### random fault injection end ###########################\n",
    "    ##################################### accuracy check ############################################\n",
    "    for layer in range(np.size(total_layer)):\n",
    "        temp_weights_back = model_vgg19.layers[layer].get_weights()\n",
    "        if(len(temp_weights_back) > 0):\n",
    "#             print('length of the temp weights back:',len(temp_weights_back))\n",
    "            model_weights_back = temp_weights_back[0]\n",
    "            model_bias_back = temp_weights_back[1]\n",
    "            shape_model_weights_back = np.shape(model_weights_back)\n",
    "            size_model_weights_back = np.size(model_weights_back)\n",
    "            resized_model_weights_back = np.reshape(model_weights_back,(size_model_weights_back))\n",
    "            resized_model_weights_back = weights_store_int_to_float[0:(layer_weight_size[j])]\n",
    "            weights_store_int_to_float = np.delete(weights_store_int_to_float,np.arange(layer_weight_size[j]))\n",
    "            j = j+1\n",
    "            model_bias_back = weights_store_int_to_float[0:(layer_weight_size[j])]\n",
    "            weights_store_int_to_float = np.delete(weights_store_int_to_float,np.arange(layer_weight_size[j]))\n",
    "            reshaped_model_weights_back = np.reshape(resized_model_weights_back,(shape_model_weights_back))\n",
    "            temp_weights_back[0] = reshaped_model_weights_back\n",
    "            temp_weights_back[1] = model_bias_back\n",
    "            model_vgg19.layers[layer].set_weights(temp_weights_back)\n",
    "            j = j+1\n",
    "#             print('current size of the total weights store int to float:',np.size(weights_store_int_to_float))\n",
    "    if np.size(weights_store_int_to_float)!=0:\n",
    "        print('weights write back dimension mismatch:',np.size(weights_store_int_to_float))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
